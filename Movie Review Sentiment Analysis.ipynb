{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd      \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"TrainData.tsv\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train,test = train_test_split(data,test_size = 0.3,random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4289</th>\n",
       "      <td>\"4456_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"This is possibly the worst film I've ever see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19621</th>\n",
       "      <td>\"914_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"(Review in English, since Swedish is not allo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14965</th>\n",
       "      <td>\"734_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"This film is a jolt of punk rock fun, from st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12321</th>\n",
       "      <td>\"10061_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"'The Curse of Frankenstein' sticks faithfully...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6269</th>\n",
       "      <td>\"4556_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I watched this film in shire joy.&lt;br /&gt;&lt;br /&gt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  sentiment                                             review\n",
       "4289    \"4456_1\"          0  \"This is possibly the worst film I've ever see...\n",
       "19621    \"914_3\"          0  \"(Review in English, since Swedish is not allo...\n",
       "14965   \"734_10\"          1  \"This film is a jolt of punk rock fun, from st...\n",
       "12321  \"10061_4\"          0  \"'The Curse of Frankenstein' sticks faithfully...\n",
       "6269    \"4556_8\"          1  \"I watched this film in shire joy.<br /><br />..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.reset_index(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4289</td>\n",
       "      <td>\"4456_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"This is possibly the worst film I've ever see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19621</td>\n",
       "      <td>\"914_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"(Review in English, since Swedish is not allo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14965</td>\n",
       "      <td>\"734_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"This film is a jolt of punk rock fun, from st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12321</td>\n",
       "      <td>\"10061_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"'The Curse of Frankenstein' sticks faithfully...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6269</td>\n",
       "      <td>\"4556_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I watched this film in shire joy.&lt;br /&gt;&lt;br /&gt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         id  sentiment  \\\n",
       "0   4289   \"4456_1\"          0   \n",
       "1  19621    \"914_3\"          0   \n",
       "2  14965   \"734_10\"          1   \n",
       "3  12321  \"10061_4\"          0   \n",
       "4   6269   \"4556_8\"          1   \n",
       "\n",
       "                                              review  \n",
       "0  \"This is possibly the worst film I've ever see...  \n",
       "1  \"(Review in English, since Swedish is not allo...  \n",
       "2  \"This film is a jolt of punk rock fun, from st...  \n",
       "3  \"'The Curse of Frankenstein' sticks faithfully...  \n",
       "4  \"I watched this film in shire joy.<br /><br />...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17500, 4), (7500, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is possibly the worst film I ve ever seen  The fact that it has a flimsy storyline is bad enough  that they ve hooked it around the subject of football violence makes it     times worse I had severe doubts about the premise of this film even before I started watching  but went into it open minded enough even to accept the way that the writers saw fit to introduce Elijah Wood s character Matt into the hooligan scene But the film throws up inaccuracy after inaccuracy  to the point that by the middle of the film each one makes you cringe harder than the time before Let s clear up a few things  Hooligans don t tend to virtually smash up their own pub before a run of the mill league game  they don t set out to kill each other  they don t ONLY wear Stone Island  and others in the crowd  hooligans or not  do   They most certainly don t  when having taken exception to a new firm member  trot off to their rival firms territory for pie and mash  And I d love to meet the hool who would go and grass on his firm s top boy to the rival firm   Although you can scratch what I said about setting to out kill each other if one does exist  Don t get me wrong I m yet to see a film on the subject that doesn t contain some fantasy whims  but this is on a par with The Firm for cluelessness I found it ironical that Wood s American nemesis is morally condemned by his character for being a cocaine user  when this is part and parcel of the British hooligan scene  The film chooses not to challenge Wood s morals and instead steers clear of any of the firm using coke I could go on  but I think I ve made my point As for the plot  it s highly unimaginative  and I m sure if I hadn t spent the entire film bemoaning the points  and more  made above then I would have guessed what was going on sooner than I did  And believe me  I was well in front I get the distinct impression this film is aimed at men  with the hope that women will enjoy the injection of emotional issues that are raised If I m right  then the makers have failed completely  It s too unrealistic to be enjoyed by anyone who knows about the scene  and I can t believe the kind of female who looks for emotive films would give a damn about any of the characters given their violent tendencies Are there any good points  Maybe the fight scenes are well choreographed and filmed  but I m rarely impressed by slow mo action  certainly not when it s a fight as the point is a ruck is rousing enough anyway There are some funny  if unrealistic moments  Wood s trip to school did raise a smile for me  But a few mildly funny moments hardly make up for watching two hours of complete fabricated dross If you re British avoid like the plague  if only not to further develop misconceptions of the scene if you re not in the know  If you re American  you may enjoy it  as it s clearly tailored to the market  But no one can deny the plot is flimsy  predictable and ultimately over the top  \n"
     ]
    }
   ],
   "source": [
    "letters_only = re.sub(\"[^a-zA-Z]\",           # The pattern to search for\n",
    "                      \" \",                   # The pattern to replace it with\n",
    "                      BeautifulSoup(train[\"review\"][0])  .get_text() )  # The text to search\n",
    "print(letters_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u'should', u'now', u'd', u'll', u'm', u'o', u're', u've', u'y', u'ain', u'aren', u'couldn', u'didn', u'doesn', u'hadn', u'hasn', u'haven', u'isn', u'ma', u'mightn', u'mustn', u'needn', u'shan', u'shouldn', u'wasn', u'weren', u'won', u'wouldn']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_words( raw_review ):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17500\n"
     ]
    }
   ],
   "source": [
    "num_reviews = train[\"review\"].size\n",
    "print(num_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 17500\n",
      "Review 2000 of 17500\n",
      "Review 3000 of 17500\n",
      "Review 4000 of 17500\n",
      "Review 5000 of 17500\n",
      "Review 6000 of 17500\n",
      "Review 7000 of 17500\n",
      "Review 8000 of 17500\n",
      "Review 9000 of 17500\n",
      "Review 10000 of 17500\n",
      "Review 11000 of 17500\n",
      "Review 12000 of 17500\n",
      "Review 13000 of 17500\n",
      "Review 14000 of 17500\n",
      "Review 15000 of 17500\n",
      "Review 16000 of 17500\n",
      "Review 17000 of 17500\n"
     ]
    }
   ],
   "source": [
    "clean_train_reviews = []\n",
    "for i in range( 0, num_reviews ):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print(\"Review %d of %d\" % ( i+1, num_reviews ))                                                                 \n",
    "    clean_train_reviews.append( review_to_words( train[\"review\"][i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'possibly worst film ever seen fact flimsy storyline bad enough hooked around subject football violence makes times worse severe doubts premise film even started watching went open minded enough even accept way writers saw fit introduce elijah wood character matt hooligan scene film throws inaccuracy inaccuracy point middle film one makes cringe harder time let clear things hooligans tend virtually smash pub run mill league game set kill wear stone island others crowd hooligans certainly taken exception new firm member trot rival firms territory pie mash love meet hool would go grass firm top boy rival firm although scratch said setting kill one exist get wrong yet see film subject contain fantasy whims par firm cluelessness found ironical wood american nemesis morally condemned character cocaine user part parcel british hooligan scene film chooses challenge wood morals instead steers clear firm using coke could go think made point plot highly unimaginative sure spent entire film bemoaning points made would guessed going sooner believe well front get distinct impression film aimed men hope women enjoy injection emotional issues raised right makers failed completely unrealistic enjoyed anyone knows scene believe kind female looks emotive films would give damn characters given violent tendencies good points maybe fight scenes well choreographed filmed rarely impressed slow mo action certainly fight point ruck rousing enough anyway funny unrealistic moments wood trip school raise smile mildly funny moments hardly make watching two hours complete fabricated dross british avoid like plague develop misconceptions scene know american may enjoy clearly tailored market one deny plot flimsy predictable ultimately top'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17500, 5000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = train_data_features.toarray()\n",
    "print(train_data_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'abc', u'abilities', u'ability', u'able', u'abraham', u'absence', u'absent', u'absolute', u'absolutely', u'absorbed', u'absurd', u'absurdity', u'abuse', u'abusive', u'abysmal', u'academy', u'accent', u'accents', u'accept', u'acceptable', u'accepted', u'access', u'accident', u'accidentally', u'accompanied', u'accomplished', u'according', u'account', u'accuracy', u'accurate', u'accused', u'achieve', u'achieved', u'achievement', u'acid', u'across', u'act', u'acted', u'acting', u'action', u'actions', u'active', u'activities', u'actor', u'actors', u'actress', u'actresses', u'acts', u'actual', u'actually', u'ad', u'adam', u'adams', u'adaptation', u'adaptations', u'adapted', u'add', u'added', u'adding', u'addition', u'adds', u'adequate', u'admire', u'admit', u'admittedly', u'adolescent', u'adorable', u'adult', u'adults', u'advance', u'advanced', u'advantage', u'adventure', u'adventures', u'advertising', u'advice', u'advise', u'affair', u'affect', u'affected', u'afford', u'aforementioned', u'afraid', u'africa', u'african', u'afternoon', u'afterwards', u'age', u'aged', u'agenda', u'agent', u'agents', u'ages', u'aging', u'ago', u'agree', u'agreed', u'agrees', u'ah']\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the words in the vocabulary\n",
    "vocab = vectorizer.get_feature_names()\n",
    "print(vocab[1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28160, u'film')\n",
      "(18733, u'one')\n",
      "(14231, u'like')\n",
      "(10739, u'good')\n",
      "(8896, u'even')\n",
      "(8888, u'time')\n",
      "(8669, u'would')\n",
      "(8526, u'story')\n",
      "(8298, u'really')\n",
      "(7933, u'see')\n",
      "(7492, u'well')\n",
      "(6886, u'much')\n",
      "(6542, u'bad')\n",
      "(6490, u'get')\n",
      "(6476, u'also')\n",
      "(6444, u'first')\n",
      "(6442, u'people')\n",
      "(6393, u'great')\n",
      "(5834, u'made')\n"
     ]
    }
   ],
   "source": [
    "# Sum up the counts of each vocabulary word\n",
    "dist = np.sum(train_data_features, axis=0)\n",
    "\n",
    "# For each, print the vocabulary word and the number of times it \n",
    "# appears in the training set\n",
    "for count, tag in sorted([(count, tag) for tag, count in zip(vocab, dist)], reverse=True)[1:20]:\n",
    "    print(count, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:  1.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 19s, sys: 316 ms, total: 2min 19s\n",
      "Wall time: 1min 13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done 200 out of 200 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Training the random forest...\")\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 200, n_jobs=2, verbose =1) \n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit( train_data_features, train['sentiment'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 4)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "# Create an empty list and append the clean reviews one by one\n",
    "num_reviews = len(test[\"review\"])\n",
    "clean_test_reviews = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21492</td>\n",
       "      <td>\"2161_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"How many of us wish that we could throw away ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9488</td>\n",
       "      <td>\"4950_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Knowing when to end a movie is just as import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16933</td>\n",
       "      <td>\"4942_7\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I have to admit that for the first half hour ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12604</td>\n",
       "      <td>\"668_7\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I just watched \\\"The Last Wave\\\" in my school...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8222</td>\n",
       "      <td>\"8689_7\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Perfect cast for a few-person drama. Simon is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index         id  sentiment  \\\n",
       "0        0  21492  \"2161_10\"          1   \n",
       "1        1   9488   \"4950_8\"          1   \n",
       "2        2  16933   \"4942_7\"          1   \n",
       "3        3  12604    \"668_7\"          1   \n",
       "4        4   8222   \"8689_7\"          1   \n",
       "\n",
       "                                              review  \n",
       "0  \"How many of us wish that we could throw away ...  \n",
       "1  \"Knowing when to end a movie is just as import...  \n",
       "2  \"I have to admit that for the first half hour ...  \n",
       "3  \"I just watched \\\"The Last Wave\\\" in my school...  \n",
       "4  \"Perfect cast for a few-person drama. Simon is...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the test set movie reviews...\n",
      "Review 5000 of 7500\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning and parsing the test set movie reviews...\")\n",
    "for i in range(0,num_reviews):\n",
    "    if( (i+1) % 5000 == 0 ):\n",
    "        print(\"Review %d of %d\" % (i+1, num_reviews))\n",
    "    clean_review = review_to_words( test[\"review\"][i] )\n",
    "    clean_test_reviews.append( clean_review )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features = vectorizer.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 5000)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=2)]: Done 200 out of 200 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Use the random forest to make sentiment label predictions\n",
    "result = forest.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Copy the results to a pandas dataframe with an \"id\" column and\n",
    "# a \"sentiment\" column\n",
    "output = pd.DataFrame({\"id\":test[\"id\"], \"sentiment\":result} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"2161_10\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"4950_8\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"4942_7\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"668_7\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"8689_7\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  sentiment\n",
       "0  \"2161_10\"          1\n",
       "1   \"4950_8\"          1\n",
       "2   \"4942_7\"          0\n",
       "3    \"668_7\"          0\n",
       "4   \"8689_7\"          1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21492</td>\n",
       "      <td>\"2161_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"How many of us wish that we could throw away ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9488</td>\n",
       "      <td>\"4950_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Knowing when to end a movie is just as import...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>16933</td>\n",
       "      <td>\"4942_7\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I have to admit that for the first half hour ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12604</td>\n",
       "      <td>\"668_7\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"I just watched \\\"The Last Wave\\\" in my school...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8222</td>\n",
       "      <td>\"8689_7\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Perfect cast for a few-person drama. Simon is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index         id  sentiment  \\\n",
       "0        0  21492  \"2161_10\"          1   \n",
       "1        1   9488   \"4950_8\"          1   \n",
       "2        2  16933   \"4942_7\"          1   \n",
       "3        3  12604    \"668_7\"          1   \n",
       "4        4   8222   \"8689_7\"          1   \n",
       "\n",
       "                                              review  \n",
       "0  \"How many of us wish that we could throw away ...  \n",
       "1  \"Knowing when to end a movie is just as import...  \n",
       "2  \"I have to admit that for the first half hour ...  \n",
       "3  \"I just watched \\\"The Last Wave\\\" in my school...  \n",
       "4  \"Perfect cast for a few-person drama. Simon is...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84813333333333329"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test['sentiment'],output['sentiment'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
